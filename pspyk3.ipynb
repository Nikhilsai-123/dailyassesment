{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhilsai-123/dailyassesment/blob/main/pspyk3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PySpark Practice Notebook\n",
        "Experimenting further with Spark Dataframes"
      ],
      "metadata": {
        "id": "vyfMDH344XZy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEO4Bljq4SDh"
      },
      "outputs": [],
      "source": [
        "#Create CSV files for the following Datasets\n",
        "\n",
        "patients\n",
        "patientId,firstName,lastName,age\n",
        "101,Alice,Smith,30\n",
        "102,Bob,Johnson,45\n",
        "103,Charlie,Williams,50\n",
        "104,John,Smith,78\n",
        "\n",
        "visits\n",
        "visitId,patientId,visitDuration\n",
        "1,101,15\n",
        "2,101,30\n",
        "3,102,45\n",
        "4,102,30\n",
        "5,104,20\n",
        "6,103,60\n",
        "7,103,50\n",
        "8,104,45\n",
        "9,,45\n",
        "10,101,30\n",
        "11,103,40\n",
        "12,,30\n",
        "13,104,25\n",
        "15,102,15"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile patients.csv\n",
        "patientId,firstName,lastName,age\n",
        "101,Alice,Smith,30\n",
        "102,Bob,Johnson,45\n",
        "103,Charlie,Williams,50\n",
        "104,John,Smith,78"
      ],
      "metadata": {
        "id": "DsnbxhdZuEo8",
        "outputId": "00f31429-10d4-499f-a0f9-64a5b1bdd9ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing patients.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile visits.csv\n",
        "visitId,patientId,visitDuration\n",
        "1,101,15\n",
        "2,101,30\n",
        "3,102,45\n",
        "4,102,30\n",
        "5,104,20\n",
        "6,103,60\n",
        "7,103,50\n",
        "8,104,45\n",
        "9,,45\n",
        "10,101,30\n",
        "11,103,40\n",
        "12,,30\n",
        "13,104,25\n",
        "15,102,15"
      ],
      "metadata": {
        "id": "8DyXXSvmuSeX",
        "outputId": "162c396b-fdaf-435c-a955-4c12de1b57dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing visits.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary spark libraries\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "\n"
      ],
      "metadata": {
        "id": "G2y2JZQY4XAi",
        "outputId": "dec0b1d8-d884-4dc5-84af-fcdcfa8808be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488490 sha256=9bf995f5ff938e54d388a6836a32a4ecdc40df8cdcf97dbaaa6e1f9e66d97919\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a SparkSession\n",
        "spark=SparkSession.builder.appName(\"SparkPractice\").getOrCreate()\n",
        "df=spark.read.option('header',True).csv('/content/patients.csv')\n",
        "df1=spark.read.option('header',True).csv('/content/visits.csv')"
      ],
      "metadata": {
        "id": "8Om-g7u26QQw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()\n",
        "df1.show()\n",
        "#Create dataframes from CSV files using enforced Schema\n",
        "patientSchema=StructType([\n",
        "    StructField('patientId',IntegerType(),True)\n",
        "    StructField('firstName',IntegerTYpe(),True)\n",
        "    StructField('lastName',IntegerType(),True)\n",
        "    StructField('age',IntegerType(),True)\n",
        "])\n",
        "visitSchema=StructType([\n",
        "    StructField('visitId',IntegerType(),True)\n",
        "    StructField('patientId',IntegerType(),True)\n",
        "    StructField('visitDuration',IntegerType(),True)\n",
        "])\n",
        "#Schems Directive [Names as string, everything else as integers]\n"
      ],
      "metadata": {
        "id": "VKkwIx3I6QOJ",
        "outputId": "4d2bd845-dc5d-4c93-d836-762aec082ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-15-3c9776dd18bc>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-3c9776dd18bc>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    StructField('patientId',IntegerType(),True)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create dataframes from CSV files using enforced Schema\n",
        "\n",
        "patientSchema = StructType([\n",
        "    StructField(\"patientId\", IntegerType(), True),\n",
        "    StructField(\"firstName\", StringType(), True),\n",
        "    StructField(\"lastName\", StringType(), True),\n",
        "    StructField(\"age\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "visitSchema = StructType([\n",
        "    StructField(\"visitId\", IntegerType(), True),\n",
        "    StructField(\"patientId\", IntegerType(), True),\n",
        "    StructField(\"visitDuration\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "df_patients = spark.read.option(\"header\", True).schema(patientSchema).csv(\"/content/patients.csv\")\n",
        "df_visits = spark.read.option(\"header\", True).schema(visitSchema).csv(\"/content/visits.csv\")\n",
        "\n",
        "df_patients.show()\n",
        "df_visits.show()\n"
      ],
      "metadata": {
        "id": "bqqwjmxxxu_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display all the valid visits\n",
        "\n",
        "\n",
        "#Fetch the total number of valid visits\n"
      ],
      "metadata": {
        "id": "B5Jx7nYN6QTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the total hours of patient visit\n"
      ],
      "metadata": {
        "id": "kI7EdZZR6QV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fetch the top two most visited patients on the basis of occurances\n"
      ],
      "metadata": {
        "id": "dLrXfV1f6QYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add a new column patientFullName & display complete dataframe\n"
      ],
      "metadata": {
        "id": "T4M1XTw56Qat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the name of patients with maximum visiting hours\n"
      ],
      "metadata": {
        "id": "Ecq6DnjA6QdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the patient with maximum visiting hours in a single visit\n"
      ],
      "metadata": {
        "id": "TSqXIP_i6QfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show the patient info according to age-seniority\n"
      ],
      "metadata": {
        "id": "Arpnz5O36Qhu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}